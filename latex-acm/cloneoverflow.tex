\documentclass{sig-alternate-05-2015}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{graphics}
\usepackage{listings}  
\usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\usepackage{multirow}
\usepackage[table]{xcolor}
\usepackage{float}
\usepackage{array}
\usepackage{ragged2e}
\newcolumntype{P}[1]{>{\RaggedRight\hspace{0pt}}p{#1}}

\usepackage{etoolbox}
\makeatletter
\patchcmd{\@makecaption}
{\scshape}
{}
{}
{}
\makeatother

\newcolumntype{"}{@{\hskip\tabcolsep\vrule width 1pt\hskip\tabcolsep}}

\lstdefinestyle{base}{
	language=C,
	emptylines=1,
	breaklines=true,
	basicstyle=\ttfamily\color{black},
	moredelim=**[is][\color{red}]{@}{@},
}

\newcommand{\squeezeup}{\vspace{-2.5mm}}
\newcommand\FIXME[1]{\textbf{FIXME: #1}}

\begin{document}

% Copyright
\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


%% DOI
%\doi{10.475/123_4}

%% ISBN
%\isbn{123-4567-24-567/08/06}

%Conference
\conferenceinfo{MSR '17}{May 20--21, 2017, Buenos Aires, Argentina}

%\acmPrice{\$15.00}

%
% --- Author Metadata here ---
%\conferenceinfo{WOODSTOCK}{'97 El Paso, Texas USA}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{Are We Reusing Outdated Code from Stack Overflow?}

\numberofauthors{1}
\author{
	\alignauthor
	$^1$Chaiyong Ragkhitwetsagul, $^1$Jens Krinke, $^2$Giuseppe Bianco \\
	\affaddr{$^1$University College London, London, UK}\\
	\affaddr{$^2$Universit√† degli Studi del Molise, Campobasso, Italy}
}


\maketitle
\begin{abstract}
This paper provides a sample of a \LaTeX\ document which conforms,
somewhat loosely, to the formatting guidelines for
ACM SIG Proceedings. It is an {\em alternate} style which produces
a {\em tighter-looking} paper and was designed in response to
concerns expressed, by authors, over page-budgets.
It complements the document \textit{Author's (Alternate) Guide to
Preparing ACM SIG Proceedings Using \LaTeX$2_\epsilon$\ and Bib\TeX}.
This source file has been written with the intention of being
compiled under \LaTeX$2_\epsilon$\ and BibTeX.

The developers have tried to include every imaginable sort
of ``bells and whistles", such as a subtitle, footnotes on
title, subtitle and authors, as well as in the text, and
every optional component (e.g. Acknowledgments, Additional
Authors, Appendices), not to mention examples of
equations, theorems, tables and figures.

To make best use of this sample document, run it through \LaTeX\
and BibTeX, and compare this source code with the printed
output produced by the dvi file. A compiled PDF version
is available on the web page to help you with the
`look and feel'.
\end{abstract}

\section{Introduction}
%The popularity of the Internet encourages tremendous amount of source code being shared online. 
Stack Overflow is a popular online programming community with 6.3 million users. It allows programmers to ask questions and give answers to programming problems. The website has found to be useful for software development and also valuable for educational purposes \cite{x}. On Stack Overflow, each conversation contains a question and answer(s).  The answers normally contain at least one code snippet as a solution to the question asked. The code snippet is usually not written directly on Stack Overflow website but copied from another location. It can be copied and modified from the problematic code snippet in the question, copied from an answerer's own code, or borrowed from other locations including open source software (OSS) systems. As a result, the process of posting and answering questions on Stack Overflow which involves copying and pasting source code can be considered as ``code cloning''. 

Code cloning is an activity of reusing source code by copying and pasting. It normally occurs in software development and account from 7\% to 23\% in typical software systems \cite{Bellon2007}. The benefits and drawbacks of clones are still controversial. Several authors state that clones lead to bug propagations and software maintenance issues \cite{Kamiya2002}, while some others have proofs that in some cases clones are not harmful than normal code or even beneficial \cite{Saini2016,Kapser2006}. Code cloning can also have side effects of violating software licenses. Carelessly cloning code from one project and reusing it in another project with different license may cause software licensing violation \cite{German2009}.

\FIXME{Add motivating example here}

In this study, we treat code snippets that are copied from software systems to Stack Overflow, and vice versa, as code clones. We call them ``online code clones''. There are three ways to create online code clones: 1) code is cloned from a software project to Stack Overflow as an example; 2) code is cloned from Stack Overflow to a software project to obtain a functionality, perform a particular task, or fixing a bug; and 3) code is implicitly cloned from one software project to another by having Stack Overflow as a medium. Online code clones can similarly lead to a problem of bug propagation. However, they are harder to locate and fix since the search scope is no longer contained in a local repository. %Since reusing source code from Stack Overflow is considered a common practice nowadays, the scale of online code cloning is more than intra or inter project clone in a local code bases. 
This is an emerging and challenging problem. Since studies in this area are still limited, we aim to address this problem in this study. %We are interested to gain more insights of online code clone in this study.

This paper makes the following  primary contributions:

\vspace{0.5ex}%
\noindent\textbf{1.~A manual study of online code clones:} 
We used two clone detection tools to discover 266,837,480 similar code fragment pairs and manually investigated x,xxx candidate clone pairs between Java code fragments obtained from Stack Overflow accepted answers and 109 Java open source projects.

\vspace{0.5ex}%
\noindent\textbf{2.~Addressing the problems of reusing source code between open source projects and Stack Overflow:} Our study shows that there are at least 48 clones that have been obviously copied from open source projects to Stack Overflow as code examples which violate their software licenses. Furthermore, 30 out of the 48 clones are outdated and dangerous for being reused.

\section{Empirical Study}
We perform an empirical study of online code clones between Stack Overflow and 63 Java open source projects to answer the following research questions: \\ 
\textbf{RQ1 (online code clones):} \textit{To what extent  source code is cloned between Stack Overflow and open source projects?} We would like to quantitatively measure the number of online code clones between Stack Overflow and open source projects. \newline
%\textbf{RQ2 (flow of online code clones):} \textit{what are the directions that source code is cloned?} If clones between the two locations exist, we would like to observe in which direction the code has been copied. Is it mostly from Stack Overflow to open source projects, or the other way around, or equally both? \newline
\textbf{RQ2 (classification of online code clones):} \textit{What are the main characteristics among the set of online code clones?} We group them into seven groups according to our pre-defined classification scheme. So we can understand the motivation of cloning. Some of the clones are copy from open source projects to Stack Overflow, while some are copied from a third-party location, and some are accidental clones containing boiler-plate code generated by IDE. \newline
\textbf{RQ3 (effects of online code clones):} \textit{Are online code clones harmful?} Is there observable problems caused by clones between Stack Overflow and open source projects?

\subsection{Experimental Framework}
The experimental framework is depicted in Figure \ref{}. We deploy two clone detection tools, Simian \cite{simian} and NICAD \cite{Roy2008,Cordy}, to locate clones between two locations: code snippets from Stack Overflow, and 63 open source projects. The clone report is pruned to contain only inter clone pairs between the two locations. In this step, all intra clone pairs within Stack Overflow and open source projects are removed. Next, clone pairs reported from the two clone detectors are matched to find agreements using Bellon's clone overlapping criteria \cite{Bellon2007}. This step generates \textbf{agreement-based clone pairs}. They are clones with highest confidence since they receive agreement from both of the tools. Then, clone pairs reported by Simian and NICAD that do not find agreement are ranked and selected. This step generates \textbf{non agreement-based clone pairs}. The non agreement-based clone pairs are clones with less confidence than agreement-based ones. Finally, agreement-based and selected non agreement-based clone pairs are looked at and classified manually.

In manual inspection process, we classify clones into categories according to their properties. This process took around three months until we successfully classified 2,371 clone pairs into categories. By ignoring clone pairs manually classified as false clones, we compare licensing information of remaining clone pairs to see if they have any licensing conflicts. Moreover, we look forward through history of the clones from the projects' versioning systems (GIT) to see if there is any changes made to the clones after it has been copied.

\subsection{Experimental Setup}
\subsubsection{Datasets}
\textbf{Stack Overflow}: we extracted 144,075 Java code snippets from accepted answers in a snapshot of Stack Overflow dump \footnote{https://archive.org/details/stackexchange} in January 2016. The archived dump has a size of 9 gigabytes. The data dump is in XML format containing information of \textit{Posts} (questions and answers) and supporting data such as user accounts and timestamps of the posts. We are interested in code snippets embedded in posts. Code snippet is a piece of code located between \texttt{<code></code>} tags. We filtered the snippets with two filtering criteria. First, we ignore snippets that are less than 6 lines since they are usually ignored by clone detection research \cite{something}. Second, we are only interested in code snippets from posts that are marked as ``accepted answer'' since they have high chances to be reused than snippets in questions and other answers. Each snippets is extracted from the dump using regular expressions and stored in a file with post ID as the file's name. We add \texttt{.java} as files' suffix so the clone detectors can recognise them. If a Stack Overflow conversation has more than one code snippet in the accepted answer, we append an indexing number starting from zero behind the ID (e.g. 45051109\_0.java, and 45051109\_1.java).

\textbf{Qualitas corpus}: we selected the latest version (20130901r) of Qualitas corpus \cite{QualitasCorpus} containing 112 Java open source projects. Three projects (\textit{eclipse}, \textit{jre}, and \textit{squirrel-sql}) do not contain source code so it has been removed from the study resulting in totally 109 projects. Details of the 109 Qualitas projects and their licenses are listed in Table \ref{t:new_and_old}.

\subsubsection{Clone Detectors}
We selected two clone detectors for this study: Simian \cite{simian} and NICAD \cite{Cordy,Roy2008}. There is a few restrictions in terms of choosing clone detection tools for this study. First, due to nature of code snippets posted on Stack Overflow, some of them are not complete Java classes or methods. Hence, the tool must be flexible enough to process code snippets which are not in a complete block or compilable. This restriction forces us to remove two well-known clone detectors; CCFinder \cite{Kamiya2002}, and DECKARD \cite{Jiang2007a}; from our study since they failed to analyse the complete 144,075 Stack Overflow snippets. Second, since the amount of code that have to be process are large \FIXME{Find SLOC of 144,075 SO snippets and 109 projects}, the clone detector must be scalable enough to execute and report clones in a reasonable amount of time. We found that both Simian and NICAD are able to handle clones in this situation with an acceptable running time.

\subsubsection{Agreement-based Clone Detection}
Since we did not have the clone oracle of the two datasets, we adopted an idea of clone agreement used in clone research \cite{Wang2013,Funaro2010} to help filtering the reported clones for manual investigation.

\section{Results}
The results of running 2 clone detectors: Simian and NiCad, to detect clones between 144,075 Stack Overflow fragments (Java accepted answers) and 109 open-source projects in Qualitas dataset is presented below. There are 2 tools selected: Simian and NiCad. They are configured using two different settings: default settings, and settings from a study by Wang et al.~\cite{Wang2013}. %Full Simian's parameter names can be found from the footnote\footnote{Simian's parameters: iChar = ignoreCharacters, iCurlB = ignoreCurlyBraces, iId = ignoreIdentifiers, iIdC = ignoreIdentifierCase, iMod = ignoreModifiers \newline iStrC = ignoreStringCase, iStr = ignoreStrings, iSbtNm = ignoreSubtypeNames, bSqBrck=balanceSquareBrackets}. 

\begin{table}[H]
	\centering
	\caption{No.~of projects in Qualitas successfully analysed by Simian and NiCad}
	\label{tab:projects_missing}
	\small
	\begin{tabular}{l|r|r|r|r}
		\hline
		%		\multicolumn{3}{c|}{Qualitas-\textit{O}} & \multicolumn{3}{c}{Qualitas-\textit{N}} \\
		%		\hline
		& Simian$_{\textrm{\textit{df}}}$ & Simian$_{\textrm{\textit{EvCl}}}$  & NiCad$_{\textrm{\textit{df}}}$ & NiCad$_{\textrm{\textit{EvCl}}}$ \\ % & Simian$_{\textrm{\textit{df/EvaClone}}}$ & NiCad$_{\textrm{\textit{df}}}$ & NiCad$_{\textrm{\textit{EvCl}}}$ \\ \hline
		\hline
		\textit{Successful} & 109 & 109 & 97 & 82 \\ %& 44 & 40 & 34 \\
		\textit{Clust.~fail} & -- & -- & 6 & 16 \\
		\textit{Renm.~fail} & -- &  -- & -- & 11 \\
		\hline
		%		& \textit{6 clustering failed} & \textit{13 clustering failed} \\ %& & \textit{4 clustering failed} & \textit{6 clustering failed} \\
		%		& cayenne   & cayenne 	\\ %& & jboss (wildfly) & ArgoUML \\
		%		& checkstyle & checkstyle \\ %& & hadoop & checkstyle \\
		%		& db-derby 	& db-derby 	\\ %& & db-derby & db-derby \\
		%		& geotools 	& geotools  \\ %& & hibernate & cayenne \\
		%		& iReport 	& iReport   \\ %& & & jena \\
		%		& hibernate & ArgoUML 	\\ %& & & geotools \\
		%		&			& castor 		\\ %& & & \\
		%		&			& drjava 		\\ %& & & \\
		%		&			& ganttproject 	\\ %& & & \\
		%		&			& ivatagroupware \\ %& & &  \\
		%		&			& jasperreports \\ %& & & \\
		%		&			& jboss 		\\ %& & & \\
		%		&			& jchempaint 	\\ %& & & \\
		%		\hline
		%		& 			&  \textit{4 renaming failed} \\ %& & & \textit{4 renaming failed} \\
		%		&			& Vuze 		\\ %& & & Vuze \\
		%		&			& aspectj 	\\ %& & & hadoop \\
		%		&			& eXoPortal 	\\ %& & & jboss (wildfly) \\
		%		&			&  hibernate 	\\ %& & & hibernate \\
		%		\hline
	\end{tabular}
\end{table}

Manual investigation of Simian's clone report showed that there were problematic 11 fragments. These fragments generate false clone containing array initialisation. Hence, they were removed from the result set before analysis.

\begin{table*}[h]
	\centering
	\caption{Statistics of clones found between Stack Overflow and Qualitas projects using Simian and NiCad}
	\label{t_simian_raw_results}
%	\resizebox{\columnwidth}{!}{%
	\small
		\begin{tabular}{l|r|r|r|r|r|r|r|r|r|r|r|r}
			\hline
			\multirow{3}{*}{Statistics} 
			& \multicolumn{3}{c|}{Simian$_{df}$} 
			& \multicolumn{3}{c|}{Simian$_{\textrm{\textit{EvCl}}}$}
			& \multicolumn{3}{c|}{NiCad$_{df}$} 
			& \multicolumn{3}{c}{NiCad$_{\textrm{\textit{EvCl}}}$} \\ \cline{2-13} 
			& \multicolumn{3}{c|}{1406 fragments} 
			& \multicolumn{3}{c|}{1360 fragments}  
			& \multicolumn{3}{c|}{1197 fragments} 
			& \multicolumn{3}{c}{12884 fragments} \\ \cline{2-13}
			%& \multicolumn{3}{c|}{iCharC,iCurlB,iIdC,iMod,iStrC} 
			%& \multicolumn{3}{c|}{iCurlB,iId,iIdC,iStr,iChar,iSbtNm,bSqBrck} 
			%& \multicolumn{3}{c|}{rename=none,abstract=none} 
			%& \multicolumn{3}{c}{rename=blind,abstract=literal} \\ %\cline{2-17}  
			& $C_{\mathrm{pairs}}$ & $C_{\mathrm{SLOC}}$ & $C_{\mathrm{\%}}$ 
			& $C_{\mathrm{pairs}}$ & $C_{\mathrm{SLOC}}$ & $C_{\mathrm{\%}}$ 
			& $C_{\mathrm{pairs}}$ & $C_{\mathrm{SLOC}}$ & $C_{\mathrm{\%}}$
			& $C_{\mathrm{pairs}}$ & $C_{\mathrm{SLOC}}$ & $C_{\mathrm{\%}}$ \\ 
			\hline
			%Removed & 11 & -- & -- & -- & 0 & -- & -- & -- & -- & -- & -- & -- & -- & -- & -- & -- \\ %& 11 & -- & -- & -- \\
			Total & 54790 & -- & -- 		& 59936722 & --	& -- 		& 127305 	& -- & -- 	& 206718663 & -- & -- \\
			Mean & 52 & 7.45 & 0.28 		& 44104 & 4.81 & 0.29 		& 106 & 9.54 & 0.25 	& 16046 & 5.31 & 0.21 \\
			Std Dev. & 147 & 3.22 & 0.23 	& 1040483 & 1.20 & 0.19 	& 209 & 3.10 & 0.18 	& 21890 & 1.92 & 0.16 \\
			Max  & 1020 & 49.00 & 0.94 		& 38223637 & 18.00 & 0.89 	& 2100 & 39.00 & 0.81 	& 442655 & 50.00 & 0.93 \\
			Min  & 1 & 5.00 & 0.01 			& 1 & 4.00 & 0.02 			& 1 & 7.00 & 0.02 		& 1 & 3.00 & 0.01 \\
			Median  & 3 & 7.00 & 0.21 		& 24 & 5.00 & 0.25 			& 20 & 8.00 & 0.19 		& 8003 & 5.00 	& 0.16 \\
			Mode  & 1 & 7.00 & 0.33 		& 1 & 4.00 & 0.50 			& 1 & 8.00 & 0.67 		& 1 & 4.00 & 0.33 \\
			\hline
		\end{tabular} %
%	}
\end{table*}

%\begin{table*}
%	\centering
%	\caption{Qualitas-\textit{N} (2016-08-05) clone results (44 new Qualitas projects)}
%	\label{t_simian_raw_results}
%%	\resizebox{\columnwidth}{!}{%
%	\small
%		\begin{tabular}{l|r|r|r|r|r|r|r|r|r|r|r|r}
%			\hline
%			\multirow{3}{*}{Statistics} 
%			& \multicolumn{3}{c|}{Simian Default settings} 
%			& \multicolumn{3}{c|}{Simian EvaClone settings} 
%			& \multicolumn{3}{c|}{NiCad Default settings} 
%			& \multicolumn{3}{c}{NiCad EvaClone settings} \\ \cline{2-13} 
%			& \multicolumn{3}{c|}{707 fragments} 
%			& \multicolumn{3}{c|}{1205 fragments} 
%			& \multicolumn{3}{c|}{1068 fragments} 
%			& \multicolumn{3}{c}{10231 fragments} \\  \cline{2-13}
%			& $C_{\mathrm{pairs}}$ & $C_{\mathrm{SLOC}}$ & $C_{\mathrm{\%}}$ 
%			& $C_{\mathrm{pairs}}$ & $C_{\mathrm{SLOC}}$ & $C_{\mathrm{\%}}$
%			& $C_{\mathrm{pairs}}$ & $C_{\mathrm{SLOC}}$ & $C_{\mathrm{\%}}$ 
%			& $C_{\mathrm{pairs}}$ & $C_{\mathrm{SLOC}}$ & $C_{\mathrm{\%}}$ \\
%			\hline
%			Total & 60,536 & -- 	& -- 	& 22,797,190 & -- 	& --  & 648,165 & -- & -- & 573,438,528 & -- & -- \\ 
%			Mean 	& 86 	& 7.37 	& 0.26 	& 18,919 	& 4.85 	& 0.28 & 607 & 9.39 & 0.25 & 47663 & 5.22 & 0.20 \\
%			Std Dev. & 217 	& 2.22 	& 0.21 	& 326,588 	& 1.31 	& 0.19 & 1,499 & 2.98 & 1.81 & 58,833 & 2.77 & 0.15 \\
%			Max 	& 1,298 & 32.00 & 0.94 & 11,127,286 & 21.00 & 0.92 & 10,550 & 36.00 & 0.84 & 1,246,598 & 250 & 0.96 \\
%			Min 	& 1 	& 5.00 	& 0.01 	& 1 & 4.00 	& 0.02 & 1 & 7 & 0.02 & 1 & 2.00 & 0.01\\
%			Median 	& 2 & 7.00 	& 0.21 	& 20		& 5.00 	& 0.25 & 33 & 8 & 0.19 & 52,077 & 5.00 & 0.15 \\
%			Mode & 1 	& 7.00 	& 0.25 	& 1 		& 4.00 	& 0.50 & 1 & 8 & 0.67 & 1 & 4.00 & 0.33 \\
%			\hline
%		\end{tabular} %
%	%}
%\end{table*}

\begin{table*}
	\centering
	\caption{109 Qualitas projects (new versions retrieved on 2016-09-27)}
	\label{t:new_and_old}
%	\resizebox{\columnwidth}{!}{%
	\small
		\begin{tabular}{l|r|r|c|c|p{3cm}|p{3cm}}
			\hline 
			Projects & Old version & New versions & Latest change & CVS & License & Notes \\
			\hline
			antlr4 & 4.0 & 4.5.4 & 25/09/2016 & git & BSD & \\
			apache-ant & 1.8.4 & 1.10.0 & 09/04/2016 & git & Apache2.0 & \\
			argouml & 0.34 & 0.35.4 & 11/01/2015 	& svn & Eclipse  1.0 & \\
			artofillusion & 2.8.1 & 3.0.2 & 27/08/2016 & svn & GPL 2.0 & \\
			aspectj & 1.6.9 & 1.8.9 & 12/05/2016 & git & Eclipse   1.0 & \\
			axion & 1.0-M2 & - & 08/03/2013 & - & Proprietary (BSD/Apache-style) & \\
			batik & 1.7 & 1.9.0 & 11/05/2016 & svn & Apache , v.2.0 & \\
			c-jdbc & 2.0.2 & - & 16/09/2005 & - & GLGPL 2.1 & \\
			castor & 1.3.1 & 1.4.2 & 17/08/2016 & git & Apache 2.0 & \\
			cayenne & 3.0.1 & 4.0.M4 &  26/09/2016 & git & Apache 2.0 & \\
			checkstyle & 5.1 & 7.2  & 23/09/2016 & git & GLGPL 2.1 \& Apache 2.0 & \textit{Cli, Logging and Beanutils} packages are from the Apache Commons project. \\
			cobertura & 1.9.4.1 & 2.1.2 & 01/06/2016 & git & GPL 2.0  & \\
			colt & 1.2.0 & - & 09/09/2014 & - & Proprietary (CERN) & Found multithreaded v. \\
			columba & 1.4 & - & 20/04/2007 & - & Mozilla   1.1  & \\
			commons-collections & 3.2.1 & 4.2 & 12/09/2016 & svn & Apache 2.0 & \\
			compiere & 330 & - & - & - & GPL 2.0 & No longer OSS \\
			db-derby & 10.6.1.0 & 10.12.1 & 13/08/2016 & svn & Apache 2.0 & \\
			displaytag & 1.2 & 2.0 & 17/08/2014 & svn & MIT  & \\
			drawswf & 1.2.9 & - & 02/04/2013 & - & GPL 2.0 & \\
			drjava & 20100913-r5387 & ??? & 03/09/2014 & svn & BSD  & Build to see version? \\
			exoportal & ??? & ??? &  & git & GLGPL 3.0 \& proprietary & Too many new projects \\
			emma & 2.0.5312 & 2.0.5312 & 09/05/2013  & - & Common   1.0 & \\
			findbugs & 1.3.9 & 3.0.1 & 06/03/2015 & - & GLGPL 2.0 & \\
			fit-java & 1.1 & - & 04/06/2013 & - & GPL 2.0 & \\
			fitlibrary & 20100806 & ??? & 29/07/2014 & git & GPL 2.0 & \\
			freecol & 0.10.7 & 0.11.6 & 26/09/2016 & git & GPL 2.0 &  \\
			freecs & 1.3.20100406 & - & 22/04/2013 & - & GPL 3.0 &   \\
			freemind & 0.9.0 & 1.0.0 & 16/08/2016 & git & GPL 2.0+ &  \\
			galleon & 2.3.0 & 2.5.6 & 29/04/2013 & - & GPL 2.0 & \\
			ganttproject & 2.0.9 & 2.8.1 & 16/08/2016 & git & GPL 3.0 &  \\
			geotools & 2.7-M3 & 16 & 27/09/2016 & git & GLGPL 2.0 & \\
			hadoop & 1.0.0 & 3.0.0-alpha2 & 26/09/2016 & git & Apache 2.0 & \\
			heritrix & 1.14.4 & - & 05/06/2013 & - & GLGPL 2.1 & \\
			hibernate & 4.2.2 & 5.2.3 & 22/09/2016 & git & GLGPL 2.1+ & \\
			hsqldb & 2.0.0 & 2.3.4 & 13/09/2016 & svn & BSD  & \\
			htmlunit & 2.8 & 2.24 & 26/09/2016 & svn & Apache 2.0 & \\
			ireport & 3.7.5 & - & 28/05/2014 & - & Affero GLGPL 3.0 & \\
			itext & 5.0.3 & 5.5.9 & 27/09/2016 & git & Affero GLGPL 3.0 & \\
			informa & 0.7.0-alpha2 & - & 07/11/2008 & - & GLGPL 2.1 \& Apache Software 1.1 & \\
			ivatagroupware & 0.11.3 & - & 27/02/2013 & - & GPL 2.0 & \\
			jfin\_datemath & R1\_0\_1 & - & 25/04/2013 & - & GPL 2.0 & \\
			joggplayer & 114s & - &  15/04/2013 & - & GPL 2.0 & \\
			jag & 6.1 & 6.2 & 08/04/2013  & - & GPL 2.0 \& BSD  & BSD  is for libraries. \\
			james & 2.2.0 & 2.3.2.1 & 14/08/2015 & - & Apache 2.0 & \\
			jasml & 0.10 & - & 08/03/2013 & - & Apache Software  & \\
			jasperreports & 3.7.4 & 6.3.1 & 27/09/2016 & git & GLGPL 3.0 &  \\
			javacc & 5.0.0 & 7.0.0 & 15/08/2016 & svn & Proprietary (Sun) & \\
			jboss (wildfly) & 5.1.0.GA & 11.0.0.Alpha1 & 27/09/2016 & git & GLGPL 2.1 & Renamed to Wildfly. \\
			jchempaint & 3.0.1 & 3.4 & 01/09/2016 & git & GLGPL 2.1+ &  \\
			jedit & 4.3.2 & 5.3.1 & 20/09/2016 & svn & GPL 2.0 &  \\
			jena & 2.6.3 & 3.1.1 & 16/09/2016 & git & Apache 2.0 & \\
			jext & 5.0 & - & 18/08/2004 & - & GPL 2.0 &  \\
			jfreechart & 1.0.13 & 1.5.0 & 29/08/2016 & git & GLGPL 2.0 &   \\
			jgraph & 5.13.0.0 & 3.6.0.0 & 07/09/2016 & git & Proprietary (mxGraph) & \\
			jgraphpad & 5.10.0.2 & - & 10/11/2006 & - & GPL   \& GLGPL (derivatives) & \\
			jgrapht & 0.8.1 & 1.0.1 & 23/09/2016 & git & GLGPL 2.1 \& Eclipse  1.0 & \\
			jgroups & 2.10.0.GA & 4.0.0 & 26/09/2016 & git & Apache 2.0 & \\
			jmoney & 0.4.4 & ??? & 27/12/2015 & git & GPL 2.0 &  \\
			jparse & 0.96 & - & 29/07/2004 & - & GLGPL 2.1 & \\
			jpf & 1.5.1 & ??? & 13/01/2012 & - & Apache 2.0 & \\
			junit & 4.11 & 4.12 & 04/12/2014 & git & Eclipse  1.0 & \\
			shiftone-jrat & 0.6 & 1-beta-1 & 17/11/2007 & svn & GLGPL 2.0 &  \\
			vuze & 4812 & 5730 & 23/09/2016 & svn & GPL 2.0 & \\
			\hline
		\end{tabular} %
%	}
\end{table*}
			
\begin{table*}
	\centering
	\caption{109 Qualitas projects (new versions retrieved on 2016-09-27)}
	\label{t:new_and_old}
	%	\resizebox{\columnwidth}{!}{%
	\small
	\begin{tabular}{l|r|r|c|c|p{3cm}|p{3cm}}
		\hline 
			Projects & Old version & New versions & Latest change & CVS & License & Notes \\
			\hline
			apache-jmeter & 2. 9 & & & & & \\
			apache-log4j & 1.2.16 & & & & & \\
			apache-maven & 3.0 & & & & & \\
			apache-roller & 4.0.1 & & & & & \\
			apache-tomcat & 7.0.2 & & & & & \\
			jhotdraw & 7.5.1 & & & & & \\
			jrefactory & 2.9.19 & & & & & \\
			jruby & 1.5.2 & & & & & \\
			jspwiki & 2.8.4 & & & & & \\
			jstock & 1.0.7c & & & & & \\
			jsxe & 04\_beta & & & & & \\
			jtopen & 7\_1 & & & & & \\
			jung2 & 2\_0\_1 & & & & & \\
			lucene & 4.3.0 & & & & & \\
			marauroa & 3.8.1 & & & & & \\
			megamek & 0.35.18 & & & & & \\
			mvnforum (mvnad) & 1.2.2 (1.0.1) & & & & & \\
			myfaces-core & 2.0.2 & & & & & \\
			nakedobjects & 4.0.0 & & & & & \\
			nekohtml & 1.9.14 & & & & & \\
			netbeans & 6.9.1 & & & & & \\
			openjms & 0.7.7-beta-1 & & & & & \\
			oscache & 2.4.1 & & & & & \\
			picocontainer & 2.10.2 & & & & & \\
			pmd & 4.2.5 & & & & & \\
			poi & 3.6 & & & & & \\
			pooka & 080505 & & & & & \\
			proguard & 4.5.1 & & & & & \\
			quartz & 1.8.3 & & & & & \\
			quickserver & 1.4.7 & & & & & \\
			quilt & 0.6-a-5 & & & & & \\
			rssowl & 2.0.5 & & & & & \\
			sablecc & 3.2 & & & & & \\
			sandmark & & & & & & \\
			spring-framework & 3.0.5 & & & & & \\
			struts2 & 2.2.1-all & & & & & \\
			sunflow & 0.07.2 & & & & & \\
			tapestry & 5.1.0.5 & & & & & \\
			trove & 2.1.0 & & & & & \\
			velocity & 1.6.4 & & & & & \\
			wct-package & 1.5.2 & & & & & \\
			webmail & 0.7.10 & & & & & \\
			weka & 3-7-9 & & & & & \\
			xalan-j & 2\_7\_1 & & & & & \\
			xerces-J & 2.10.0 & & & & & \\
			xmojo & 5.0.0 & & & & & \\
			\hline 
		\end{tabular} %
%	}
\end{table*}

\subsection{Agreement based clone pairs vs. Non agreement based clone pairs}

The agreement-based clone pairs are the ones discovered using Bellon's \textit{good}-match(0.7) and \textit{ok}-match(0.7) criteria as listed in  Table \ref{t_agreed_good_clone_pairs}. Non-agreement based clone pairs are the ones that are solely reported by a single tool. The agreement-based pairs provide higher confident that they are real clones than the non-agreement based ones.

\subsection{Agreement based clone pairs}
For agreement-based clone pairs, we use a threshold of 0.7 for both \textit{good} and \textit{ok}-match. A visualisation of \textit{good}-match common clone pairs between four sets of parameter settings can be seen from Figure \ref{fig:venn4_orig_good}. There are 1,357 unique \textit{good}-match pairs. The distribution of 10,139 \textit{ok}-match pairs, which subsume the \textit{good}-match pairs, is depicted in Figure \ref{fig:venn4_orig_ok}.

Nevertheless,  NiCad produced renaming and clustering errors for some of the settings. This resulted in not all 109 projects had NiCad clone reports. For NiCad default settings (NiCad$_{\textrm{\textit{df}}}$), 6 projects had clustering failed errors. For NiCad EvaClone settings (NiCad$_{\textrm{\textit{EvCl}}}$), 4 projects had renaming failed errors and 13 projects had clustering failed errors as depicted in Table \ref{tab:projects_missing}. So these projects are also missing from agreed clone pairs. \FIXME{Report the errors to NiCad creator.}

%\FIXME{Maybe no longer needed?} We are interested in discovering reused code in the latest versions of Qualitas projects. So, we downloaded the newest release of each project and found 44 of them having newer updates. Then, we reran the experiment again on these 44 projects. Several projects triggered NiCad problem of clustering and renaming again as listed in Table \ref{tab:projects_missing}. The agreed clone pairs using Bellon's \textit{good}-match(0.7) and \textit{ok}-match(0.7) criteria of this new dataset are also listed in Table \ref{t_agreed_good_clone_pairs}. 

\begin{table}[H]
	\centering
	\caption{Distribution of agreement-based clone pairs reported using Bellon's criteria}
	\label{t_agreed_good_clone_pairs}
	\small
	\begin{tabular}{l|l|r|r}
		\hline
		\multicolumn{2}{c|}{Tool} & \multicolumn{2}{c}{Qualitas-\textit{O}} \\
		\hline
		Simian & NiCad & \textit{good}-match & \textit{ok}-match \\
		%\hline
		%Settings & Simian$_{\mathrm{\textit{default}}}$ & Simian$_{\mathrm{\textit{EvaClone}}}$ & Simian$_{\mathrm{\textit{default}}}$ & Simian$_{\mathrm{\textit{EvaClone}}}$ \\ % & Simian$_{\mathrm{\textit{cloplag}}}$ \\
		\hline
		\textit{default} & \textit{default} & 10 	& 3800 \\ 
		\textit{default} & \textit{EvaClone} 	& 26 	& 1017 \\ 
		\textit{EvaClone} 	& \textit{default} 	& 10 	& 88 \\
		\textit{EvaClone} 	& \textit{EvaClone} 	& 2228 & 19777 \\ 
		\hline
		\multicolumn{2}{l|}{Total} & 2274 & 24682 \\
		\hline
		\multicolumn{2}{l|}{Total (unique)} & 2261 & 23868 \\
		\hline
	\end{tabular}
\end{table}

\begin{figure}
		\centering
		\includegraphics[width=0.9\linewidth]{venn4_pairs_good_pt1+2}
		\caption{\textit{good}-match(0.7) pairs}
		\label{fig:venn4_orig_good}
\end{figure}

\begin{figure}
		\centering
		\includegraphics[width=0.9\linewidth]{venn4_pairs_ok_pt1+2}
		\caption{\textit{ok}-match(0.7) pairs}
		\label{fig:venn4_orig_ok}
\end{figure}

\subsection{Manual investigation of agreement-based clone pairs}
%\subsubsection*{\textbf{Qualitas-\textit{O} (v. 2013-09-01r)}}

%\subsection{Investigation of agreed \textit{good} and \textit{ok}-match clone pairs}

\begin{table*}
	\centering
	\caption{Classifications of clone creation}
	\label{tab:classification_scheme}
	\begin{tabular}{|c|p{13cm}|}
		\hline 
		Category & Descriptions \\ 
		\hline 
		A & Code in Stack Overflow is copied from Qualitas (Q $\rightarrow$ S). \\ 
		\hline 
		A' & Code in Qualitas is copied from Stack Overflow (S $\rightarrow$ Q). \\ 
		\hline 
		B & Code is copied either from each other or a third source (unknown) (S $\leftrightarrow$ Q $\vee$ (T $\rightarrow$ S $\wedge$ T $\rightarrow$ Q)).
		\\ 
		\hline 
		C & Code in both places are copied from a third source T (known) (T $\rightarrow$ S $\wedge$ T $\rightarrow$ Q).
		\\ 
		\hline 
		D & Code is a boiler-plate or IDE auto-generated.
		\\ 
		\hline 
		E & Code in both places initialise a similar/the same object; extend the same class/its subclass; implement the same interface.
		\\ 
		\hline 
		F & Accidental similarity, false clone \\ 
		\hline 
	\end{tabular} 
\end{table*}

The classification scheme is described in Table \ref{tab:classification_scheme} and the classification results are shown in Table \ref{tab:classification_good_o}. We have manually investigated all of the 1,357 \textit{good-match} ones reported by agreement of four different Simian and NiCad settings.  However, for the \textit{ok-match}, we could not investigate all of the 10,139 pairs manually.  According to the distribution of category from \textit{good-match} results, we can see that Simian$_{\textrm{\textit{EvCl}}}$--NiCad$_{\textrm{\textit{EvCl}}}$ produces a large number, 1,338, of false positive results (D, E, and F). Thus, we decided to leave them out of the manual investigation of \textit{ok-match} pairs. There are totally 608 \textit{ok-match} pairs that were investigated. The 39 true positive pairs found are combinations of 8 unique Stack Overflow fragments, and 9 unique Qualitas Java files from 6 different projects.

Since we are not certain about the direction of copying in the B-classified pairs, we checked the modification time of each Java file in Qualitas project and compare it to the timestamp of Stack Overflow answers. We found that all Stack Overflow code fragments were posted after their respectively similar Java files in Qualitas project. This means that the copying can only be either (1) Q $\rightarrow$ S or (2) from a third source to both S and Q independently.

%\textbf{Qualitas-\textbf{N}:} We decided to filter out the agreed clone pairs reported by agreement of Simian$_{\mathrm{\textit{EvaClone}}}$-NiCad$_{\mathrm{\textit{EvaClone}}}$ altogether due to its large number of false positive. With the remaining 3 agreements, we did manual investigation of agreed \textit{ok}-match clone pairs from agreements of Simian$_{df}$-NiCad$_{df}$, Simian$_{df}$-NiCad$_{\mathrm{\textit{EvaClone}}}$, and Simian$_{\mathrm{\textit{EvaClone}}}$-NiCad$_{df}$. We had not done any investigation of \textit{good}-match since there were no \textit{good}-match pairs for these 3 agreements. The number of pairs that have been looked at is 6,706 (excluding duplicates). The results are shown in Table.

\begin{table*}
	\centering
	\caption{Qualitas-\textit{O}: Classification results of \textit{good-} and \textit{ok}-match pairs which excludes the subsumed \textit{good}-match and Simian$_{\mathrm{\textit{EvaClone}}}$-NiCad$_{\mathrm{\textit{EvaClone}}}$ pairs.}
	\label{tab:classification_good_o}
	\small
	\resizebox{2.1\columnwidth}{!}{%
	\begin{tabular}{|l"r|r|r|r|r|r|r|r"r|r|r|r|r|r|r"r|r|r|r|}
		\hline
		Classificaiton & A & A' & B & C & \textbf{Sum} & S$_{u}$ & Q$_u$ & Q$_{up}$ & D  & E & F & \textbf{Sum} & S$_{u}$ & Q$_u$ & Q$_{up}$ & \textbf{Total}  & S$_{u}$ & Q$_u$ & Q$_{up}$\\ 
		\hline 
		\multirow{1}{*}{\textit{good-match(0.7)}}  & 1 & 0 & 4  & 3 & \textbf{8} & 7 & 6 & 6 & 58  & 6 & 2189 & \textbf{2253} & 81 & 693 & 58 & \textbf{2261} & 87 & 699 & 59 \\
		\multirow{1}{*}{\textit{ok-match(0.7)}}  & 8 & 0 & 33  & 8 & \textbf{49} & 12 & 14 & 10 & 4459 & 35 & 82 & \textbf{4576} & 99 & 136 & 29 & \textbf{4625} & 110 & 150 & 33 \\
		\hline
	\end{tabular} 
}
\end{table*}

%\begin{table}
%	\centering
%	\caption{Distribution of classification category A--F according to \textit{good}- and \textit{ok-}match pairs. S denotes Simian and N denotes NiCad tool.}
%	\label{tab:good_classification}
%	\small
%	\begin{tabular}{|l|r|r|r|r|r|r|r|r|}
%		\hline 
%		Category   & A   & 	A'   & 	B   & C   & D   &	E   &	F   & Total  \\
%		\hline
%		\hline
%		\multicolumn{9}{|c|}{\textit{good}-match pairs} \\
%		\hline
%		S$_{df}$--N$_{df}$   & 1 & 0 & 1 & 0 & 1 & 4 & 0 & 7 \\
%		S$_{df}$--N$_{\textrm{\textit{EvCl}}}$   & 1 & 0 & 0 & 3 & 14 & 1 & 1 & 20 \\
%		S$_{\textrm{\textit{EvCl}}}$--N$_{df}$   & 0 & 0 & 3 & 0 & 7 & 0 & 0 & 10 \\
%		S$_{\textrm{\textit{EvCl}}}$--N$_{\textrm{\textit{EvCl}}}$   & 0 & 0 & 1 & 0 & 20 & 0 & 2188 & 2228 \\
%		\hline
%		Total   &   2   &   0   &  2   &  6   &   26   &   10   & 1320  & 1366 \\
%		Total (unique)  &   1   &   0   &  1   &  3   &   26   &   6   & 1320  & 1352 \\
%		\hline
%		\hline 
%%		Category   																										& A   	& 	A' 	& 	B  & C	   & D   	&	E   &	F   & Total  \\
%%		\hline
%		\multicolumn{9}{|c|}{\textit{ok}-match pairs} \\
%		\hline
%		S$_{df}$--N$_{df}$        & 3 	& 0 	& 12	& 6 	& 3755  & 8	& 7  &  3791 \\
%		S$_{df}$--N$_{\textrm{\textit{EvCl}}}$   	& 8 	& 0 	& 28	& 4	& 904 & 29  & 32 &  1005 \\
%		S$_{\textrm{\textit{EvCl}}}$--N$_{df}$   	& 0 	& 0 	& 0 	& 0 	 & 29 	  & 0 		& 24 	& 53 \\
%		\hline
%		Total   &   11  &   0   &  32   &  10   &   712   &   30   & 63  & 858 \\
%		Total (unique)  &   8  &   0   &  23   &  8   &  480  &  28  & 61  & 608 \\
%		\hline
%	\end{tabular} 
%\end{table}

\subsection{Non-agreement based clone pairs}
In the preliminary stage of our experiment, we found that there are 41 Stack Overflow fragments reported by Simian with default configurations. However, only 10 of them appear in the new results using tool's agreement. Thus, we further investigated the clone pairs reported by Simian and NiCad but \textit{without} an agreement. 

With our 4 settings, we decided to investigate only 2 settings, Simian$_{df}$, and NiCad$_{df}$, and drop Simian$_{\mathrm{\textit{EvaClone}}}$ and NiCad$_{\mathrm{\textit{EvaClone}}}$ due to their large number of false positives as shown in Table \ref{tab:good_classification} and \ref{tab:ok_classification}. With the 2 selected settings, we investigated clone pairs having the minimum clone size of 10 SLOC as they are meaningful and tend to be real clone in modern clone detection \cite{Sajnani2016}. 

For Simian$_{df}$, there were 9,383 clone pairs reported by the tool. Out of 9,383 pairs, 140 of them are the ones found in \textit{ok-}pairs using agreement-based detection. We filtered the results further by removing false positives such as similar equals(), hashCode() methods, getters and setters out by using regular expression. We managed to remove 8,956 pairs using this method. Eventually, there were 287 clone pairs remaining for manual investigation. For NiCad$_{df}$, we obtained 7,040 clone pairs to look at which is infeasible for manual investigation. Hence, result filtering was also needed. However, regular expressions could not be used effectively as in Simian's case since NiCad allowed clones that are different at keywords/variable names or even added/deleted lines. So we decided to filter the results by selecting pairs that pass stricter clone criteria with $\mathrm{UPI} = 0.2$. By reducing the UPI to 0.2, there were totally 166 pairs left. Out of 166, 52 are \textit{ok}-pairs and 114 are remaining pairs for manual check (18 pairs are from \textit{cayenne} and \textit{iReport} that could not be analysed using UPI = 0.3). The statistics of the clones and classification results are reported in Table \ref{tab:classification_indv_stats} and \ref{tab:classification_indv}.

%We selected only Stack Overflow fragment and Qualitas files that have never been looked at before in the previous investigation. If many clone pairs having the same Stack Overflow fragment and Qualitas file, we keep only the largest one. The reason for having this criteria is that we found a lot of duplicate clone pairs with the same classifications from either Stack Overflow fragments or Qualitas files. The classification results are shown in Table \ref{tab:classification_indv}. 

\begin{table}
	\centering
	\caption{Statistics of Simian$_{df}$ and NiCad$_{df}$ non agreement-based clone pairs.}
	\label{tab:classification_indv_stats}
	\small
	\begin{tabular}{l|r|r|r|r}
		\hline 
		Tool & Clone pairs & \textit{ok}-pairs & filtered & remaining \\ 
		%\hline 
		%\multirow{1}{*}{\textit{Simian$_{df}$}-1} & 9383 & 140 & 8951 & 292 \\
		%\multirow{1}{*}{\textit{Simian$_{df}$}-2} & 9042 & 0 & 8539 & 503 \\
		\hline
		\multirow{1}{*}{\textit{Simian$_{df}$}} & 18425 & 140 & 17490 & 795 \\
		\hline
%		\multirow{1}{*}{\textit{NiCad$_{df}$}-1} & 7040  & 226 & 6700 & 114 \\
%		\multirow{1}{*}{\textit{NiCad$_{df}$}-2} & 22187  & 152 & 21990 & 45 \\
		\multirow{1}{*}{\textit{NiCad$_{df}$}} & 29227  & 378 & 28690 & 159 \\
		\hline
	\end{tabular} 
\end{table}

\subsection{Manual investigation of non agreement-based clone pairs}
%\subsubsection*{\textbf{Qualitas-\textit{O} (v. 2013-09-01r)}}
We performed manual investigation of the clone pairs reported by Simian$_{df}$ and NiCad$_{df}$ in the same way as the agreement-based clone pairs. The results of the manual investigation is reported in Table \ref{tab:classification_indv}.

\begin{table*}
	\centering
	\caption{Classification results of 795 Simian$_{df}$ and 159 NiCad$_{df}$ non agreement-based clone pairs.}
	\label{tab:classification_indv}
	\small
	\resizebox{2.1\columnwidth}{!}{%
	\begin{tabular}{|l|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|r|}
		\hline 
		Tool/Classification & A & A' & B & C & \textbf{Sum} & S$_{u}$ & Q$_{u}$ & Q$_{up}$ & D & E & F & \textbf{Sum}  & S$_{u}$ & Q$_{u}$ & Q$_{up}$ & \textbf{Total} & S$_{u}$ & Q$_{u}$  & Q$_{up}$  \\ 
		\hline 
%		\multirow{1}{*}{\textit{Simian$_{df}$}} & 35 & 0 & 90 & 8 & \textbf{133} & 68 & 59 & 23 & 13 & 12 & 134 & \textbf{159} & 39 & 72 & 23 & \textbf{292} & 103 & 125 & 31 \\
%		\multirow{1}{*}{\textit{Simian$_{df}$}} & 36 & 0 & 229 & 3 & \textbf{268} & 76 & 151 & 14 & 169 & 52 & 14 & \textbf{235} & 92 & 119 & 22 & \textbf{503} & 164 & 261 & 24 \\
		\multirow{1}{*}{\textit{Simian$_{df}$}} & 71 & 0 & 319 & 11 & \textbf{401} & 138 & 210 & 37 & 182 & 64 & 148 & \textbf{394} & 120 & 191 & 45 & \textbf{795} & 246 & 386 & 55 \\
		\hline
%		\multirow{1}{*}{\textit{NiCad$_{df}$}} & 4  & 0 & 5 & 0 & \textbf{9} & 9 & 5 & 4 & 24 & 3 & 78 & \textbf{105} & 41 & 39 & 12 & \textbf{114} & 48 & 44 & 14 \\ 
%		\multirow{1}{*}{\textit{NiCad$_{df}$}} & 0  & 0 & 10 & 0 & \textbf{10} & 7 & 8 & 5 & 6 & 3 & 26 & \textbf{35} & 17 & 16 & 8 & \textbf{45} & 24 & 24 & 9 \\ 
		\multirow{1}{*}{\textit{NiCad$_{df}$}} & 4  & 0 & 15 & 0 & \textbf{19} & 15 & 13 & 9 & 30 & 6 & 104 & \textbf{140} & 51 & 55 & 20 & \textbf{159} & 66 & 68 & 23 \\ 
		\hline
		%		\multirow{1}{*}{\textit{NiCad$_{df}$}*} & 4  & 0 & 1 & 0 & \textbf{5} & 4 & 5 & 3 & 23 & 1 & 67 & \textbf{91} & 28 & 31 & 10 & \textbf{96} & 33 & 37 & 13 \\ 
		%		\hline
	\end{tabular} 
}
\end{table*}

%\subsection{Summary of true online clone pairs}
\begin{table}[H]
	\centering
	\caption{Numbers of true positive online clone pairs found by manual investigation}
	\label{tab:classification_true_pairs_summary}
	\small
	\begin{tabular}{l|r|r|r|r|r}
		\hline 
		Tool & A & A' & B & C & Total \\
		\hline
		\textit{good}-pairs & 1 & 0 & 4 & 3 & 8 \\
		\textit{ok}-pairs & 8 & 0 & 33 & 8 & 49 \\
%		Simian$_{df}$ pairs-1 & 35 & 0 & 90 & 8 & 133 \\
%		Simian$_{df}$ pairs-2 & 36 & 0 & 229 & 3 & 268 \\
		Simian$_{df}$ pairs & 71 & 0 & 319 & 11 & 401 \\
%		NiCad$_{df}$ pairs & 4 & 0 & 5 & 0 & 9 \\
%		NiCad$_{df}$ pairs-2 & 0 & 0 & 10 & 0 & 10 \\
		NiCad$_{df}$ pairs & 4 & 0 & 15 & 0 & 19 \\
		\hline 
		Total & 84 & 0 & 371 & 22 & 477 \\
		\hline
	\end{tabular} 
\end{table}

\begin{figure*}
	\centering
	\includegraphics[width=1\linewidth]{Sankey_proj}
	\caption{Relationships between 184 true online code clone found between Stack Overflow and Qualitas projects}
	\label{fig:sankey}
\end{figure*}

%\subsubsection{Qualitas-\textit{N} (v. 2016-08-05)}

\section{Effects of online code clone}

In this study, we are interested in the effects of online code clones to software development. From the manual investigation of 184 true online clone pairs, we found that there are two potential issues: stale online code, and software licensing violation.

\subsection{Issue~1:~stale online code clones}
Stale online code occurs when a piece of code has been copied from a software project to Stack Overflow, and later it has been changed in the original project. However, in this situation, the copy is still unchanged. Since the code were updated due to various possible reasons including bug fixing, this can cause a problem if developers reuse stale online code from Q\&A websites such as Stack Overflow. They might also introduce the same unfixed bug(s) into the software. To discover stale online code, we focus on the true online clone pairs that are copied in the direction of Q $\rightarrow$ S (class-\textit{A} online clone pairs) in Table \ref{tab:classification_true_pairs_summary} which results in 48 pairs selected. We restricted it further to only the ones having versioning system so we can trace changes made to these clone pairs. Fortunately, all of the pairs were from projects with either git or svn so we did not remove any pair from this set. 

%Our intuition behind his issue comes from a situation where a piece of code has been copied from a Qualitas project and posted on Stack Overflow. Later, that piece of code has been modified further to accommodate changes in the projects (or any other reasons). However, even the code in Qualitas project is already updated, the one posted on Stack Overflow is not changed. This results in outdated online code which can cause problems when programmers copy and use it in their projects.

%We decided to ignore NiCad results from this analysis due to its failure of clone clustering and renaming on some projects.  Thus, the 39 projects are the ones that can be analysed by Simian, have newer versions than the versions in Qualitas-\textit{O}, and have code version control system (either git or svn). %After filtering, there are 141 pairs removed because 45 of them do not have new versions (7 from c-jdbc, 21 from Compiere, 7 from heritrix, and 10 from iReport) and 4 of them we could not find source code with version control (2 from findbugs, 1 from jag, and 1 from jgraphpad). Finally there were 134  pairs remaining. %We are interested in clone pairs that were changed after they appeared on Stack Overflow.

The manual investigation of 48 class-A online clone pairs reveals that there are 30 stale clones. They are clone pairs that were copied from Qualitas projects to Stack Overflow and marked as \textit{accepted} answers.  The investigation results are described in Table \ref{tab:stale_code}.

\begin{table}
	\centering
	\caption{Summary of stale code clones found}
	\label{tab:stale_code}
	\small
	\begin{tabular}{l|r|r|r}
		\hline 
		Project & Pairs & Stale & Fresh \\
		\hline
		apache-ant & 1 & 0 & 1 \\
		aspectj & 2 & 2 & 0 \\
		hadoop & 14 & 9 & 5 \\
		hibernate & 16 & 5 & 11 \\
		jasperreports & 2 & 2 & 0 \\
		jfreechart & 4 & 4 & 0 \\
		jgraph & 5 & 5 & 0 \\
		jgrapht & 1 & 0 & 1 \\
		junit & 3 & 3 & 0 \\
		\hline
		Total & 48 & 30 & 18 \\
		\hline
	\end{tabular} 
\end{table}

\begin{table*}
	\centering
	\caption{30 stale code clones in Stack Overflow found by a manual investigation}
	\label{tab:stale_code_details}
	\small
	\begin{tabular}{r|l|r|c|l}
		\hline 
		No. & File & Stack Overflow Q\&A & Changes made & Date \\
		\hline
		1 & aspectjtools1.6.9-src/../Agent.java & 18303692 & alteration & 2015-09-08 \\
		2 & aspectjweaver1.6.9-src/../Agent.java & 18303692 & alteration & 2015-09-08 \\
		3 & hadoop-1.0.0/../WritableComparator.java & 22315734 & alteration & 2014-11-20 \\
		4 & hadoop-1.0.0/../StringUtils.java & 801987 & alteration & 2013-02-04 \\
		5 & hadoop-1.0.0/../DBCountPageView.java & 21702608 & alteration & 2011-06-12 \\
		6 & hadoop-1.0.0/../DBCountPageView.java & 21702608 & alteration & 2011-06-12 \\
		7 & hadoop-1.0.0/../LineRecordReader.java & 16180910 & alteration & 2011-07-25 \\
		8 & hadoop-1.0.0/../LineRecordReader.java & 16180910 & alteration & 2011-07-25 \\
		9 & hadoop-1.0.0/../JobSubmissionFiles.java & 14845581 & alteration & 2012-06-25 \\
		10 & hadoop-1.0.0/../TextOutputFormat.java & 16928749 & alteration & 2011-06-12 \\
		11 & hadoop-1.0.0/../TestJobCounters.java & 18833798 & alteration & 2011-06-12 \\
		12 & hibernate-release-4.2.2.Final/../SettingsFactory.java & 8257554 & removal & 2011-03-11 \\
		13 & hibernate-release-4.2.2.Final/../Example.java & 24924255 & alteration & 2013-04-23 \\
		14 & hibernate-release-4.2.2.Final/../SQLServer2005LimitHandler.java.java & 23967852 & alteration & 2013-04-23 \\
		15 & hibernate-release-4.2.2.Final/../ConnectionProviderInitiator.java & 15168494 & alteration & 2016-02-24 \\
		16 & hibernate-release-4.2.2.Final/../SchemaUpdate.java & 23520731 & alteration & 2016-02-05 \\
		17 & jasperreports-3.7.4/../JRVerifier.java & 8037824 & removal & 2011-05-20 \\
		18 & jasperreports-3.7.4/../JRVerifier.java & 8037824 & alteration & 2013-12-08 \\
		19 & jasperreports-3.7.4/../SpiderWebPlot.java & 21998949 & alteration & 2013-11-22 \\
		20 & jasperreports-3.7.4/../SpiderWebPlot.java & 21998949 & alteration & 2013-11-22 \\
		21 & jasperreports-3.7.4/../AbstractXYItemRenderer.java & 12936580 & alteration & 2016-01-16 \\
		22 & jfreechart-1.0.13/../KeyToGroupMap.java & 16058183 & alteration & 2013-07-03 \\
		23 & jgraph-latest-bsd-src/../GroupingRemoving.java & 6722760 & rewriting & 2005 \\
		24 & jgraph-latest-bsd-src/../HelloWorld.java & 6722760 & rewriting & 2005 \\
		25 & jgraph-latest-bsd-src/../HelloWorld.java & 6722760 & rewriting & 2005 \\
		26 & jgraph-latest-bsd-src/../HelloWorld.java & 6722760 & rewriting & 2005 \\
		27 & jgraph-latest-bsd-src/../HelloWorld.java & 6722760 & rewriting & 2005 \\
		28 & junit-4/org/junit/Assert.java & 23586872 & alteration & 2015-05-12 \\
		29 & junit-4/../ExpectException.java & 8802082 & alteration & 2014-05-26 \\
		30 & junit-4/../ExternalResource.java & 7504040 & alteration & 2016-06-25 \\
		\hline
	\end{tabular} 
\end{table*}

\subsection{Issue~2:~clones with software licensing violations}
Software licensing is vital in software industry. Violation of software license can have a major impact to the delivery of the software and also lead to legal issues. It is an emerging area that software engineering research community is paying attention to. For example, there are studies of automatic technique to identify software licensing from source code files \cite{German2010} and the evolution of licenses in open source projects \cite{DiPenta2010}.

In our study, we tackle another possible situation of software licensing issue caused by code cloning to Q\&A websites. We found that there are at least 48 pieces of code have been copied from 9 open source projects to Stack Overflow as examples. These 9 open source projects come with software licenses. However, the licensing information are mostly missing from these clones. If developers copy and reuse these pieces of code in their projects, a licensing conflict can quietly happen without realisation of the developers. 

%\section{Investigation of Missing A/B Clone Pairs Reported by Simian$_{df}$}
%We investigated the 41 clone pairs previously reported by Simian with default configurations and manually investigated. The 41 pairs were searched for in 4 new results sets: Simian$_{df}$, Simian$_{\mathrm{\textit{EvaClone}}}$, NiCad$_{df}$, NiCad$_{\mathrm{\textit{EvaClone}}}$. The investigation results are shown in Table \ref{tab:search}.
%
%\begin{table}
%	\centering
%	\caption{Results of matching the original 41 Simian(default) pairs in the pretty-printed result sets}
%	\label{tab:search}
%	\begin{tabular}{l|r|r}
%		\hline 
%		Settings & Found & Not found \\ 
%		\hline 
%		Simian$_{df}$  &  40 & 1* \\ 
%		\hline 
%		Simian$_{\mathrm{\textit{EvaClone}}}$ & 0 & 41  \\ 
%		\hline 
%		NiCad$_{df}$  & 17 & 24 \\ 
%		\hline 
%		NiCad$_{\mathrm{\textit{EvaClone}}}$ &  24 & 17 \\ 
%		\hline 
%	\end{tabular} 
%\end{table}
%
%The single missing Stack Overflow fragment (19051537\_0.java) (denoted by *) is one of the 11 false clones generated by Simian. It is removed from the results of the pretty-printed version because it is an outlier. The rest are missing because of different parameter settings.
%
%\section{Simian's Parameters}
%
%We have carefully investigated the effects of the Simian's parameter \texttt{-balanceSquareBrackets+}. I found that it works in the expected way of handling a pair of brackets (\texttt{[},\texttt{]}) that span over multiple lines. For example, the two code fragments in Figure \ref{fig:two_frags} would match by having \texttt{-balanceSquareBrackets+} enabled. However, the \texttt{-balanceSquareBrackets+} parameter only works on a small testing environment having toy programs or only small pairs from the full datasets. It does not work with the full complete set of 144,075 Stack Overflow fragments and Qualitas projects. Please find the summary of all the testing scenarios in Table \ref{tab:summary}. %I found that this pair is missing if I turned on \texttt{-balanceSquareBrackets+}.
%
%\noindent\begin{figure*}
%	\scriptsize
%	\begin{lstlisting}[frame=single,style=base]
%	1   public class MagicSquare {                           public class MagicSquare2 {
%	2       private int[][] square;                              @private int[@
%	3       private boolean[] possible;                                      @][@
%	4       private int totalSqs;                                            @] square;@
%	5       private int sum;                                     private boolean[] possible;
%	6       private int numsquares;                              private int totalSqs;
%	7       public static void main ( String[] args ) {          private int sum;
%	8       MagicSquare m = new MagicSquare ( 3 );               private int numsquares;
%	9                                                            public static void main ( String[] args ) {
%	10                                                           MagicSquare m = new MagicSquare ( 3 );
%	\end{lstlisting}
%	\caption{Two identical fragments with only differences in locations of the square brackets. All 7 lines are reported by Simian if \small\texttt{-balanceSquareBrackets+} \normalsize is enabled. If not, the clone pairs is reported as \newline (MagicSquare.java [3,8], MagicSquare2.java [5,10]).} 
%	\label{fig:two_frags}
%\end{figure*}
%
%\begin{table*}
%	\caption{Simian's \texttt{-balanceSquareBrackets+} (\texttt{-bsb+}) is observed to have unpredictable behaviours when running against big datasets. $\textrm{\textit{CP}}_2$ means the reported clone(s) do not contain lines having dislocated brackets ($L_b$) (i.e. $\textrm{\textit{CP}}_2 = \textrm{\textit{CP}}_1 - L_b$).}
%	\label{tab:summary}
%	\centering
%	\small\begin{tabular}{l|p{6cm}|c|c|c}
%		\hline 
%		\multirow{2}{*}{\textbf{Project 1}} & \multirow{2}{*}{\textbf{Project 2}} & \textbf{Dislocated} & \multirow{2}{*}{\textbf{-bsb+}} & \textbf{Clones pair} \\ 
%		& & \textbf{brackets?} & & \textbf{reported} \\
%		\hline
%		\hline
%		\multicolumn{5}{l}{\textit{Only run Simian against the pair}} \\
%		\hline
%		MagicSquare.java & MagicSquare\_exact\_copy.java & no & 0,1 & $\textrm{\textit{CP}}_1$ \\
%		MagicSquare.java & MagicSquare2.java & yes & 0 & $\textrm{\textit{CP}}_2$ \\ 
%		MagicSquare.java & MagicSquare2.java & yes & 1 & $\textrm{\textit{CP}}_1$ \\
%		\hline
%		%\hline
%		%\multicolumn{5}{c}{\textit{Only run Simian against the pair}} \\
%		%\hline
%		stackoverflow/4298836\_0.java & Qualitas/aoisrc281/../ExprModule.java & no & 0 & $\textrm{\textit{CP}}_3$ \\ 
%		stackoverflow/4298836\_0.java & Qualitas/aoisrc281/../ExprModule.java & no & 1 & $\textrm{\textit{CP}}_3$ \\ 
%		stackoverflow/4533682\_1.java & Qualitas/cobertura-1/../TouchCollector.java & no & 0 & $\textrm{\textit{CP}}_4$ \\ 
%		stackoverflow/4533682\_1.java & Qualitas/cobertura-1/../TouchCollector.java & no & 1 & $\textrm{\textit{CP}}_4$ \\ 
%		\hline 
%		\hline
%		\multicolumn{5}{l}{\textit{Run Simian against the complete stackoverflow data and the project}} \\
%		\hline
%		stackoverflow/4298836\_0.java & Qualitas/aoisrc281/../ExprModule.java & no & 0 & $\textrm{\textit{CP}}_3$ \\ 
%		\cellcolor{red!10}stackoverflow/4298836\_0.java & \cellcolor{red!10}Qualitas/aoisrc281/../ExprModule.java & \cellcolor{red!10}no & \cellcolor{red!10}1 & \cellcolor{red!10}-- \\ 
%		\hline
%		stackoverflow/4533682\_1.java & Qualitas/cobertura-1/../TouchCollector.java & no & 0 & $\textrm{\textit{CP}}_4$ \\ 
%		\cellcolor{red!10}stackoverflow/4533682\_1.java & \cellcolor{red!10}Qualitas/cobertura-1/../TouchCollector.java & \cellcolor{red!10}no & \cellcolor{red!10}1 & \cellcolor{red!10}-- \\
%		\hline 
%	\end{tabular} 
%\end{table*}

\section{Threats to Validity}

\section{Related Work}
\begin{itemize}
	\item Code clones 
		\begin{itemize}
			\item Definition: Baxter et al. \cite{Baxter1998}
			\item Comparison of clone detectors: \cite{Roy2008, Ragkhitwetsagul2016,Svajlenko2014}
			\item NiCad \cite{Roy2008,Cordy}
			\item Simian \cite{simian}
			\item Clone taxonomy \cite{Kapser2003}
			\item Clone evolution \cite{Pate2013,Mondal2011}
			\item Comparing Quality Metrics for Cloned and non cloned Java Methods : A Large Scale Empirical Study \cite{Saini2016}.
		\end{itemize}
	\item Agreement-based Clone Detection
	\begin{itemize}
		\item Bellon's framework \cite{Bellon2007}.
		\item EvaClone \cite{Wang2013}
		\item Hybrid \cite{Funaro2010}
	\end{itemize}
	\item Software licensing
	\begin{itemize}
		\item Code siblings \cite{German2009}, Ninka -- Automatic indification of SW license \cite{German2010}, Evolution of SW licensing \cite{DiPenta2010}
	\end{itemize}

	\item Stack Overflow
	\begin{itemize}
		\item Code example \cite{Nasehi2012}
		\item Search for code in Stack Overflow \cite{Diamantopoulos2015,Keivanloo2014,Park2014}
	\end{itemize}
\end{itemize}

\section{Conclusions}
This paragraph will end the body of this sample document.
Remember that you might still have Acknowledgments or
Appendices; brief samples of these
follow.  There is still the Bibliography to deal with; and
we will make a disclaimer about that here: with the exception
of the reference to the \LaTeX\ book, the citations in
this paper are to articles which have nothing to
do with the present subject and are used as
examples only.
%\end{document}  % This is where a 'short' article might terminate

%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}
This section is optional; it is a location for you
to acknowledge grants, funding, editing assistance and
what have you.  In the present case, for example, the
authors would like to thank Gerald Murray of ACM for
his help in codifying this \textit{Author's Guide}
and the \textbf{.cls} and \textbf{.tex} files that it describes.

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{sigproc}  

\end{document}
